{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# This talk is about\n",
    "- `dask` (which is awesome)\n",
    "- NNs `keras` (which I've not managed to wrap my head around)\n",
    "\n",
    "### but mostly about failure\n",
    "\n",
    "## @mattilyra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Networks are not easy to understand and implement\n",
    "- Neural network are the new state-of-the-art (sort of)\n",
    "- Easy to use (no faffing around with feature extraction or selection - sort of)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### the plan was to\n",
    "- take the datasets from Felix and apply deep learning\n",
    "- take already published research and implement their model in `keras`\n",
    "- alternatively take an already existing implementation and use that\n",
    "- run NNs on GPUs on AWS and tell everyone how cool everything is  !!\n",
    "\n",
    "### Problems\n",
    "- very little data (probably won't see an improvement)\n",
    "    - maybe something interesting will happen with word embeddings\n",
    "\n",
    "## No experience in applying NNs to anything (other than toy problems during BSc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What my time was spent on\n",
    "- Setting up AWS machinery (1 hour)\n",
    "    - No GPU because AWS decided I shouldn't be using one\n",
    "    - I exceeded my \"maximum limit of 0 GPU nodes\"\n",
    "    \n",
    "- Installing software and downloading datasets (3 hours)\n",
    "- Preprocessing data (6 hours)\n",
    "- Trying to get `keras` to do _something_ / _anything_ (30 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-18T17:11:37.479760",
     "start_time": "2016-10-18T17:11:37.322511"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'filename': 'data/txt/17001.txt',\n",
       "  'in_writing': False,\n",
       "  'sequence': 169,\n",
       "  'sitzung': 1,\n",
       "  'speaker': None,\n",
       "  'speaker_cleaned': None,\n",
       "  'speaker_fp': None,\n",
       "  'speaker_party': None,\n",
       "  'text': 'Beifall',\n",
       "  'type': 'poi',\n",
       "  'wahlperiode': 17},\n",
       " {'filename': 'data/txt/17001.txt',\n",
       "  'in_writing': False,\n",
       "  'sequence': 168,\n",
       "  'sitzung': 1,\n",
       "  'speaker': 'Präsident Dr. Norbert Lammert',\n",
       "  'speaker_cleaned': 'Dr. Norbert Lammert',\n",
       "  'speaker_fp': 'norbert-lammert',\n",
       "  'speaker_party': None,\n",
       "  'text': 'im Rahmen eines kleinen Empfangs in der Fraktionsebene Gelegenheit zum Gespräch mit den neu gewählten Mitgliedern des Präsidiums ist.',\n",
       "  'type': 'chair',\n",
       "  'wahlperiode': 17})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.bag as db\n",
    "import json\n",
    "\n",
    "records = db.read_text('../pydata_hackathon/bundestag/unravelled/*.json').map(json.loads)\n",
    "records.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-18T17:12:15.089653",
     "start_time": "2016-10-18T17:12:07.115350"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3683"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.pluck('speaker_cleaned').distinct().count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-18T17:12:53.095402",
     "start_time": "2016-10-18T17:12:44.969352"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 35),\n",
       " ('Meine Damen und Herren, der französische Bischof und Staatsmann Talleyrand sagte einmal',\n",
       "  3),\n",
       " ('Zu den Abläufen hat der damalige Finanzminister gesagt', 10),\n",
       " ('Fakt ist', 10),\n",
       " ('Ich wollte nur gerade darauf hinweisen, dass es aus meiner Sicht zwei große Schwierigkeiten gibt',\n",
       "  3)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_freq = records.pluck('speaker_cleaned').frequencies()\n",
    "speaker_freq.compute()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-18T17:15:04.888766",
     "start_time": "2016-10-18T17:14:56.805859"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dr. Norbert Lammert', 10234),\n",
       " ('Petra Pau', 9029),\n",
       " ('Eduard Oswald', 5080),\n",
       " ('Hubertus Heil', 4131),\n",
       " ('Volker Kauder', 4110),\n",
       " ('Claudia Roth', 3981),\n",
       " ('Gerda Hasselfeldt', 3438),\n",
       " ('Ulla Schmidt', 3424),\n",
       " ('Elke Ferner', 3310),\n",
       " ('Renate Künast', 3212)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers = (records\n",
    "           .pluck('speaker_cleaned')\n",
    "           .filter(lambda speaker: speaker is not None and 0 < len(speaker) < 20))\n",
    "speaker_freq = speakers.frequencies()\n",
    "speaker_freq.topk(10, key=lambda x: x[1]).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-18T17:26:56.694744",
     "start_time": "2016-10-18T17:26:27.118901"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 7.3 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "speakers = (records\n",
    "           .pluck('speaker_cleaned')\n",
    "           .filter(lambda speaker: speaker is not None and len(speaker) < 20)\n",
    "           .frequencies()\n",
    "           .topk(10, key=lambda x: x[1])).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-18T17:18:00.445902",
     "start_time": "2016-10-18T17:18:00.441143"
    },
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-18T17:29:36.208855",
     "start_time": "2016-10-18T17:28:49.846130"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 11.5 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "files = glob.glob('../pydata_hackathon/bundestag/unravelled/*.json')\n",
    "speaker_freq = defaultdict(lambda: 0)\n",
    "for f in files:\n",
    "    with open(f, 'r') as fh:\n",
    "        for line in fh:\n",
    "            item = json.loads(line)\n",
    "            speaker = item['speaker_cleaned']\n",
    "            if speaker is not None and len(speaker) < 20:\n",
    "                speaker_freq[speaker] += 1\n",
    "sorted(list(speaker_freq.items()), key=lambda i: i[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- `dask.bag` is much faster\n",
    "\n",
    "#### BUT\n",
    "\n",
    "- calling `json.loads` per line is expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![assets/char_cnn_title.png](assets/char_cnn_title.png)\n",
    "\n",
    "_Character-level Convolutional Networks for Text Classification*_\n",
    "\n",
    "(Zhang et. al, Neural Information Processing Systems 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![assets/char_cnn_model.png](assets/char_cnn_model.png)\n",
    "\n",
    "_Character-level Convolutional Networks for Text Classification*_\n",
    "\n",
    "(Zhang et. al, Neural Information Processing Systems 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![assets/char_cnn_keymodules.png](assets/char_cnn_keymodules.png)\n",
    "\n",
    "_Character-level Convolutional Networks for Text Classification*_\n",
    "\n",
    "(Zhang et. al, Neural Information Processing Systems 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-20T10:50:42.477511",
     "start_time": "2016-10-20T10:50:42.148097"
    },
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# this model is almost certainly wrong - please don't use it\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.layers.core import Dense, Flatten, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution1D(256, 7, border_mode='same', input_length=1014, input_dim=132))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_length=3, stride=1, border_mode='valid'))\n",
    "\n",
    "model.add(Convolution1D(256, 7, border_mode='same', input_dim=132))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_length=3, stride=1, border_mode='valid'))\n",
    "\n",
    "model.add(Convolution1D(256, 3, border_mode='same', input_dim=132))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_length=3, stride=1, border_mode='valid'))\n",
    "\n",
    "model.add(Convolution1D(256, 3, border_mode='same', input_dim=132))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_length=3, stride=1, border_mode='valid'))\n",
    "\n",
    "model.add(Convolution1D(256, 3, border_mode='same', input_dim=132))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_length=3, stride=1, border_mode='valid'))\n",
    "\n",
    "model.add(Convolution1D(256, 3, border_mode='same', input_dim=132))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_length=3, stride=1, border_mode='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024, init='normal', input_dim=\n",
    "    activation='relu', weights=None, W_regularizer=None,\n",
    "    b_regularizer=None, activity_regularizer=None, W_constraint=None,\n",
    "    b_constraint=None, bias=True))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1024, init='normal',\n",
    "    activation='relu', weights=None, W_regularizer=None,\n",
    "    b_regularizer=None, activity_regularizer=None, W_constraint=None,\n",
    "    b_constraint=None, bias=True))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "n_classes = len(records.pluck('speaker_party').distinct().compute())\n",
    "model.add(Dense(n_classes, input_dim=256, init='normal',\n",
    "    activation='softmax', weights=None, W_regularizer=None,\n",
    "    b_regularizer=None, activity_regularizer=None, W_constraint=None,\n",
    "    b_constraint=None, bias=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# data preprocessing ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- character quantization to 1-hot character vectors\n",
    "- truncate all documents to N=1014 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-18T17:56:42.028022",
     "start_time": "2016-10-18T17:56:42.018068"
    },
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "/home/ubuntu/.conda/envs/keras/lib/python3.5/site-packages/keras/engine/training.py in standardize_input_data(data, names, shapes, check_batch_dim, exception_prefix)\n",
    "    106                                         ' to have shape ' + str(shapes[i]) +\n",
    "    107                                         ' but got array with shape ' +\n",
    "--> 108                                         str(array.shape))\n",
    "    109     return arrays\n",
    "    110 \n",
    "\n",
    "Exception: Error when checking model target: expected dense_21 to have shape (None, 22) but got array with shape (1, 1)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](assets/sentence_cnn_title.png)\n",
    "\n",
    "_Convolutional Neural Networks for Sentence Classification_\n",
    "\n",
    "(Kim, Empirical Methods in Natural Language Processing 2014)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](./assets/sentence_cnn_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "https://github.com/bwallace/CNN-for-text-classification (Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# data preprocessing ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- truncate all sentences to N=30 words\n",
    "- get word vectors from `spacy` and stack sentences into\n",
    "  - `1x9000` matrices (doesn't work)\n",
    "  - `30x300` matrices (doesn't work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "\n",
    "/usr/data/miniconda3/envs/keras/lib/python3.5/site-packages/keras/engine/training.py in standardize_input_data(data, names, shapes, check_batch_dim, exception_prefix)\n",
    "     95                                 ' to have ' + str(len(shapes[i])) +\n",
    "     96                                 ' dimensions, but got array with shape ' +\n",
    "---> 97                                 str(array.shape))\n",
    "     98             for j, (dim, ref_dim) in enumerate(zip(array.shape, shapes[i])):\n",
    "     99                 if not j and not check_batch_dim:\n",
    "\n",
    "Exception: Error when checking model input: expected input to have 2 dimensions, but got array with shape (11, 30, 300)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Never figured out what the dimensionality of the input matrix `X` needs to be !! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Finally - a comparison \n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "IMDB Movie Reviews (Accuracy)\n",
    "\n",
    "Keras example CNN model: 0.89\n",
    "SVM (SGD): 0.88\n",
    "MNB: 0.84\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- The comparison isn't really fair to any of the models\n",
    "  - the NN doesn't have enough training data\n",
    "  - the document representation is not very good for SVM and NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# WHYY?!\n",
    "\n",
    "- can someone please tell what is going on?\n",
    "- was I wrong to use `keras`?\n",
    "- good resources:\n",
    "    - http://wildml.com\n",
    "    - http://github.com (but you need to find the correct repo)\n",
    "\n",
    "- https://github.com/zhangxiangxiao/Crepe (Torch 7)\n",
    "- https://github.com/yoonkim/CNN_sentence (Theano)\n",
    "- https://github.com/bwallace/CNN-for-text-classification (Keras)\n",
    "- https://github.com/alexander-rakhlin/CNN-for-Sentence-Classification-in-Keras (Keras)\n",
    "- http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/ (TensorFlow)\n",
    "\n",
    "## @mattilyra"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
